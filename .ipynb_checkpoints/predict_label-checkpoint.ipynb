{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wf1Sy9AJUdl"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "xQb79rVpJYAf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import razdel\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7eyXTIczJ2C2",
    "outputId": "56469c0c-dc7e-47a2-ea75-87bcd17d3e3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert_tokenizer = transformers.BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "tuned_RuBERT = transformers.BertForSequenceClassification.from_pretrained(\n",
    "    'DeepPavlov/rubert-base-cased', \n",
    "    output_attentions=True,\n",
    "    pad_token_id=bert_tokenizer.eos_token_id,\n",
    "    num_labels=2,\n",
    "    return_dict = True\n",
    ").to(device)\n",
    "\n",
    "weights_file = 'weights/tuned_RuBERT_common.pt'\n",
    "tuned_RuBERT.load_state_dict(torch.load(weights_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "Rmb4Fn2cK-PG"
   },
   "outputs": [],
   "source": [
    "def filter_text(text):\n",
    "    line = razdel.tokenize(text.lower())\n",
    "    line = [token.text for token in line]\n",
    "    filtered_line = ' '.join([token for token in line if token.isalpha()])\n",
    "        \n",
    "    return filtered_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "vk5dGzg_KV4o"
   },
   "outputs": [],
   "source": [
    "def sample_batch(text, tokenizer=bert_tokenizer, max_length=16):\n",
    "    tokenizer_output = tokenizer.encode_plus(\n",
    "            filter_text(text), max_length = max_length,\n",
    "            return_tensors = 'pt', padding = 'max_length')\n",
    "        \n",
    "    return {\n",
    "            \"input_ids\": tokenizer_output['input_ids'].squeeze(0)[:max_length], \n",
    "            \"mask\": tokenizer_output['attention_mask'].squeeze(0)[:max_length],\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "hwkW3f6cV6Tj"
   },
   "outputs": [],
   "source": [
    "def predict(texts):\n",
    "    inputs = []\n",
    "    mask = []\n",
    "    for text in texts:\n",
    "        batch = sample_batch(text)\n",
    "        inputs.append(batch['input_ids'].numpy().tolist())\n",
    "        mask.append(batch['mask'].numpy().tolist())\n",
    "\n",
    "    inputs = torch.tensor(inputs)\n",
    "    mask = torch.tensor(mask)\n",
    "    tuned_RuBERT.eval()\n",
    "    with torch.no_grad():\n",
    "      outputs = tuned_RuBERT(input_ids = inputs.to(device), attention_mask = mask.to(device))\n",
    "      probas = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    result = []\n",
    "    for proba in probas:\n",
    "        result.append({\"negative\": proba.tolist()[0], \"positive\": proba.tolist()[1]})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "e7T6znjuWz62"
   },
   "outputs": [],
   "source": [
    "messages = ['черт я так устала не могу', 'ура я довольный и счастливый']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WesGNZO3aAbs",
    "outputId": "efba97d3-1332-4563-bbe6-dda4181ff077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "черт я так устала не могу -> {'negative': 0.985421359539032, 'positive': 0.014578700996935368}\n",
      "ура я довольный и счастливый -> {'negative': 0.015193315222859383, 'positive': 0.9848067164421082}\n"
     ]
    }
   ],
   "source": [
    "results = predict(messages)\n",
    "for message, sentiment in zip(messages, results):\n",
    "    # черт я так устала не могу -> {'negative': 0.985421359539032, 'positive': 0.014578700996935368}\n",
    "    # ура я довольный и счатсливый -> {'negative': 0.03474540263414383, 'positive': 0.9652546048164368}\n",
    "    print(message, '->', sentiment)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "predict_label.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
